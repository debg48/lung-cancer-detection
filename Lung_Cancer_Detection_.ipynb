{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7LVlN9lBK++HdUjvVZCSZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debg48/lung-cancer-detection/blob/main/Lung_Cancer_Detection_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "roEk2A4GoyF-"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = 'https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images'"
      ],
      "metadata": {
        "id": "i2LCl0cHqgD2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(dataset_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIeg98JAqjiQ",
        "outputId": "defb7cd6-6c67-464f-ec46-a813255c8858"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: debg48\n",
            "Your Kaggle Key: ··········\n",
            "Downloading chest-ctscan-images.zip to ./chest-ctscan-images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119M/119M [00:06<00:00, 18.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "59qfj2iPqs-D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image \n",
        "\n",
        "\n",
        "img = Image.open ('/content/chest-ctscan-images/Data/train/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa/000003 (3).png')\n",
        "img.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0c3SOM7tanU",
        "outputId": "bc8b403e-5f34-4751-a996-affa447a4334"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(437, 258)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen=ImageDataGenerator(\n",
        "                           rescale=1./255.,\n",
        "                           validation_split=0.15,\n",
        "                           zoom_range=0.1,\n",
        "                           horizontal_flip=True,\n",
        "                           fill_mode='nearest'                           \n",
        "                        )"
      ],
      "metadata": {
        "id": "7he8BrCJrwPP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator=datagen.flow_from_directory(\n",
        "                    directory=\"/content/chest-ctscan-images/Data/train\",\n",
        "                    subset=\"training\",\n",
        "                    color_mode='rgb',\n",
        "                    class_mode='categorical',\n",
        "                    batch_size=32,\n",
        "                    shuffle=True,\n",
        "                    seed=0,\n",
        "                    target_size=(240,240)\n",
        "              )\n",
        "\n",
        "valid_generator=datagen.flow_from_directory(\n",
        "                    directory=\"/content/chest-ctscan-images/Data/valid\",\n",
        "                    subset=\"validation\",\n",
        "                    color_mode='rgb',\n",
        "                    class_mode='categorical',\n",
        "                    batch_size=32,\n",
        "                    shuffle=True,\n",
        "                    seed=0,\n",
        "                    target_size=(240,240)\n",
        "              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl1Ifywxr3C9",
        "outputId": "0f36c9b2-cc5c-4a15-aad9-cbfdeac5750a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 522 images belonging to 4 classes.\n",
            "Found 9 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "num_classes = 4"
      ],
      "metadata": {
        "id": "SXfo0tKOwb9j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_resnet_model():\n",
        "    pretrained_model = tf.keras.applications.ResNet50V2(include_top=False , weights='imagenet')\n",
        "    pretrained_model.trainable = True\n",
        "    model = tf.keras.Sequential([\n",
        "        pretrained_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "        tf.keras.layers.Dense(num_classes, activation = 'softmax')\n",
        "    ])\n",
        "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "M_VX1Dw7vK0Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint"
      ],
      "metadata": {
        "id": "Bw0x8MB3xTUQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_START = 1.0e-5\n",
        "LR_MAX = 2.5e-5 \n",
        "LR_MIN = LR_START\n",
        "LR_RAMPUP_EPOCHS = 1\n",
        "LR_SUSTAIN_EPOCHS = 0 # 3\n",
        "LR_EXP_DECAY = 0.80\n",
        "\n",
        "def lrfn(epoch):\n",
        "    if epoch < LR_RAMPUP_EPOCHS:\n",
        "        lr = LR_START + (epoch * (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS)\n",
        "    elif epoch < (LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS):\n",
        "        lr = LR_MAX\n",
        "    else:\n",
        "        lr = LR_MIN + (LR_MAX - LR_MIN) * LR_EXP_DECAY ** (epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)\n",
        "#    print('For epoch', epoch, 'setting lr to', lr)\n",
        "    return lr\n",
        "\n",
        "    \n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='best_weights.hdf5',\n",
        "                             save_weights_only=True,\n",
        "                             monitor='val_accuracy',\n",
        "                             mode='max',\n",
        "                             save_best_only=True)"
      ],
      "metadata": {
        "id": "uHOoSD-8xZjf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_res = create_resnet_model()"
      ],
      "metadata": {
        "id": "4HcLWeXnxeSL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21717ac2-4389-4b6d-a181-c6f9a1313058"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94668760/94668760 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "#STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "hist_incep = model_res.fit(train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=5,\n",
        "                    callbacks = [lr_callback, checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcxzACdUxrYk",
        "outputId": "94a89ef5-a830-4ad6-d719-7d091c96a57a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 1/5\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.3307 - accuracy: 0.3735"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/16 [==============================] - 60s 705ms/step - loss: 1.3307 - accuracy: 0.3735 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 2.5e-05.\n",
            "Epoch 2/5\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.9926 - accuracy: 0.6245"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/16 [==============================] - 9s 562ms/step - loss: 0.9926 - accuracy: 0.6245 - lr: 2.5000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 2.2e-05.\n",
            "Epoch 3/5\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7456 - accuracy: 0.7388"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/16 [==============================] - 9s 567ms/step - loss: 0.7456 - accuracy: 0.7388 - lr: 2.2000e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 1.9600000000000002e-05.\n",
            "Epoch 4/5\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6050 - accuracy: 0.8184"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/16 [==============================] - 10s 570ms/step - loss: 0.6050 - accuracy: 0.8184 - lr: 1.9600e-05\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 1.7680000000000004e-05.\n",
            "Epoch 5/5\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4902 - accuracy: 0.8673"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/16 [==============================] - 11s 659ms/step - loss: 0.4902 - accuracy: 0.8673 - lr: 1.7680e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZvAPQXZ4xy69"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}